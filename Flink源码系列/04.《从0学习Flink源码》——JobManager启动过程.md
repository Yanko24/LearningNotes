### 《从0学习Flink源码》——JobManager启动过程

#### 1. 前言

上一篇文章我们从脚本出发，查看了flink集群的启动流程，今天我们来看看通过flink-daemon中调用的类`StandaloneSessionClusterEntrypoint`的一个启动过程。

#### 2. 入口类StandaloneSessionClusterEntrypoint

该类位于`flink-runtime`模块下，位于包`entrypoint`中，我们可以先看看这个类的一个继承结构：

![](https://yanko24-note.oss-cn-zhangjiakou.aliyuncs.com/flink-sourcecode/StandaloneSessionClusterEntrypoint.png)

从上图可以看到`StandaloneSessionClusterEntrypoint`继承自`SessionClusterEntrypoint`，而`SessionClusterEntrypoint`又继承自`ClusterEntrypoint`，`ClusterEntrypoint`实现了`FatalErrorHandler`和`AutoCloseableAsync`两个接口。

接下来我们看看这个类的main方法，看看main方法中到底做了什么事情？

```java
public static void main(String[] args) {
    // startup checks and logging
    // 记录有关环境的信息，如代码修订、当前用户、Java版本和JVM参数
    EnvironmentInformation.logEnvironmentInfo(
            LOG, StandaloneSessionClusterEntrypoint.class.getSimpleName(), args);
    // 注册一些处理信号处理器
    SignalHandler.register(LOG);
    // 安装安全关机挂钩。JVM在被终止前被允许关闭的最长时间是5秒
    JvmShutdownSafeguard.installAsShutdownHook(LOG);

    // 解析传入的参数args 1️⃣
    final EntrypointClusterConfiguration entrypointClusterConfiguration =
            ClusterEntrypointUtils.parseParametersOrExit(
                    args,
                    new EntrypointClusterConfigurationParserFactory(),
                    StandaloneSessionClusterEntrypoint.class);
    // 用拿到的EntrypointClusterConfiguration对象构建一个Configuration对象 2️⃣
    Configuration configuration = loadConfiguration(entrypointClusterConfiguration);

    // 将Configuration对象传入构造一个StandaloneSessionClusterEntrypoint对象 3️⃣
    StandaloneSessionClusterEntrypoint entrypoint =
            new StandaloneSessionClusterEntrypoint(configuration);

    // 运行ClusterEntrypoint的runClusterEntrypoint方法 4️⃣
    ClusterEntrypoint.runClusterEntrypoint(entrypoint);
}
```

接下来我们深入的看看图中序号对应部分的源码，看看如何解析参数并利用其构建一个配置对象，最后将配置对象作为入惨构造`StandaloneClusterSessionEntrypoint`对象并启动集群。

#### 3. parseParametersOrExit

该方法位于`CluterEntrypoingUtils`类中，用于解析传入的错误，在解析错误时调用System.exit打印错误信息。

```java
/**
 * Parses passed String array using the parameter definitions of the passed {@code
 * ParserResultFactory}. The method will call {@code System.exit} and print the usage
 * information to stdout in case of a parsing error.
 *
 * @param args The String array that shall be parsed.
 * @param parserResultFactory The {@code ParserResultFactory} that collects the parameter
 *     parsing instructions.
 * @param mainClass The main class initiating the parameter parsing.
 * @param <T> The parsing result type.
 * @return The parsing result.
 */
public static <T> T parseParametersOrExit(
        String[] args, ParserResultFactory<T> parserResultFactory, Class<?> mainClass) {
    final CommandLineParser<T> commandLineParser = new CommandLineParser<>(parserResultFactory);

    try {
        // 调用CommandLineParser对象的parse方法解析参数args
        return commandLineParser.parse(args);
    } catch (Exception e) {
        LOG.error("Could not parse command line arguments {}.", args, e);
        commandLineParser.printHelp(mainClass.getSimpleName());
        System.exit(ClusterEntrypoint.STARTUP_FAILURE_RETURN_CODE);
    }

    return null;
}
```

接下来我们继续看看`CommandLineParser`对象的方法parse是如何解析args参数的，parse方法之后调用了`flink-runtime`模块下`entrypoint.parser`包下的`CommandLineParser#parse`方法，parse方法调用了`commons-cli`组件中`DefaultParser#parse`方法进行了具体args的参数解析。大致的流程如下：

![](https://yanko24-note.oss-cn-zhangjiakou.aliyuncs.com/flink-sourcecode/StandaloneSessionClusterEntrypoint-parseArgs.png)

#### 4. loadConfiguration

传入`EntrypointClusterConfiguration`对象构造一个`Configuration`对象，其中主要获取configDir创建了一个`Configuration`对象，并根据`EntrypointClusterConfiguration`的对象中包含的`RestPort`和`HostName`的值情况，将restport和hostname的值添加到`Configuration`对象中。

```java
protected static Configuration loadConfiguration(
        EntrypointClusterConfiguration entrypointClusterConfiguration) {
    // 从EntrypointClusterConfiguration对象中获取动态配置属性，传入创建一个Configuration对象 1️⃣
    final Configuration dynamicProperties =
            ConfigurationUtils.createConfiguration(
                    entrypointClusterConfiguration.getDynamicProperties());
    // 传入config的目录以及动态的属性配置对象dynamicProperties构建一个Configuration对象 2️⃣
    final Configuration configuration =
            GlobalConfiguration.loadConfiguration(
                    entrypointClusterConfiguration.getConfigDir(), dynamicProperties);

    // 从EntrypointClusterConfiguration获取restport配置信息
    final int restPort = entrypointClusterConfiguration.getRestPort();

    if (restPort >= 0) {
        // 设置RestPort端口
        configuration.setInteger(RestOptions.PORT, restPort);
    }

    // 从EntrypointClusterConfiguration获取hostname配置信息
    final String hostname = entrypointClusterConfiguration.getHostname();

    if (hostname != null) {
        // 设置HostName信息
        configuration.setString(JobManagerOptions.ADDRESS, hostname);
    }

    return configuration;
}
```

我们再继续深入看看`ConfigurationUtils.createConfiguration`和`GlobalConfiguration.loadConfiguration`方法的内部实现。

##### 1. ConfigurationUtils.createConfiguration

```java
/**
 * Creates a new {@link Configuration} from the given {@link Properties}.
 *
 * @param properties to convert into a {@link Configuration}
 * @return {@link Configuration} which has been populated by the values of the given {@link
 *     Properties}
 */
@Nonnull
public static Configuration createConfiguration(Properties properties) {
    final Configuration configuration = new Configuration();

    final Set<String> propertyNames = properties.stringPropertyNames();

    for (String propertyName : propertyNames) {
        configuration.setString(propertyName, properties.getProperty(propertyName));
    }

    return configuration;
}
```

根据传入的`Properties`对象去构建一个新的`Configuration`对象，循环将`Properties`对象中的值添加到`Configuration`对象中，并返回。

##### 2. GlobalConfiguration.loadConfiguration

```java
/**
 * Loads the configuration files from the specified directory. If the dynamic properties
 * configuration is not null, then it is added to the loaded configuration.
 * 从指定的目录加载配置文件，如果动态配置属性不是null，则将其也加入Configuration配置对象中
 *
 * @param configDir directory to load the configuration from
 * @param dynamicProperties configuration file containing the dynamic properties. Null if none.
 * @return The configuration loaded from the given configuration directory
 */
public static Configuration loadConfiguration(
        final String configDir, @Nullable final Configuration dynamicProperties) {

    // 判断config配置目录是否为空，如果为空就跑出异常信息
    if (configDir == null) {
        throw new IllegalArgumentException(
                "Given configuration directory is null, cannot load configuration");
    }

    final File confDirFile = new File(configDir);
    // 如果配置目录的文件不存在，抛出异常信息
    if (!(confDirFile.exists())) {
        throw new IllegalConfigurationException(
                "The given configuration directory name '"
                        + configDir
                        + "' ("
                        + confDirFile.getAbsolutePath()
                        + ") does not describe an existing directory.");
    }

    // get Flink yaml configuration file
    // 从configDir目录下获取flink-conf.yaml文件对象
    final File yamlConfigFile = new File(confDirFile, FLINK_CONF_FILENAME);

    // 如果flink-conf.yaml文件不存在就抛出异常
    if (!yamlConfigFile.exists()) {
        throw new IllegalConfigurationException(
                "The Flink config file '"
                        + yamlConfigFile
                        + "' ("
                        + yamlConfigFile.getAbsolutePath()
                        + ") does not exist.");
    }

    // 调用loadYAMLResource方法解析flink-conf.yaml文件的内容，并返回Configuration对象
    Configuration configuration = loadYAMLResource(yamlConfigFile);

    // 如果动态配置dynamicProperties不为null，则将其加入到Configuration配置中
    if (dynamicProperties != null) {
        configuration.addAll(dynamicProperties);
    }

    return configuration;
}
```

这个方法先检查`confiDir`是否存在，如果不存在则抛出异常，之后继续判断`configDir`目录下是否存在`flink-conf.yaml`文件，不存在则抛出异常，如果存在就调用`loadYAMLResource`解析其内容并生成`Configuration`配置对象，之后将动态配置`dynamicProperties`的内容也加入到`Configuration`对象中。继续看看`loadYAMLResource`方法的具体实现：

```java
/**
 * Loads a YAML-file of key-value pairs.
 *
 * <p>Colon and whitespace ": " separate key and value (one per line). The hash tag "#" starts a
 * single-line comment.
 *
 * <p>Example:
 *
 * <pre>
 * jobmanager.rpc.address: localhost # network address for communication with the job manager
 * jobmanager.rpc.port   : 6123      # network port to connect to for communication with the job manager
 * taskmanager.rpc.port  : 6122      # network port the task manager expects incoming IPC connections
 * </pre>
 *
 * <p>This does not span the whole YAML specification, but only the *syntax* of simple YAML
 * key-value pairs (see issue #113 on GitHub). If at any point in time, there is a need to go
 * beyond simple key-value pairs syntax compatibility will allow to introduce a YAML parser
 * library.
 *
 * @param file the YAML file to read from
 * @see <a href="http://www.yaml.org/spec/1.2/spec.html">YAML 1.2 specification</a>
 */
private static Configuration loadYAMLResource(File file) {
    final Configuration config = new Configuration();

    try (BufferedReader reader =
            new BufferedReader(new InputStreamReader(new FileInputStream(file)))) {

        String line;
        int lineNo = 0;
        while ((line = reader.readLine()) != null) {
            lineNo++;
            // 1. check for comments
            String[] comments = line.split("#", 2);
            String conf = comments[0].trim();

            // 2. get key and value
            if (conf.length() > 0) {
                String[] kv = conf.split(": ", 2);

                // skip line with no valid key-value pair
                if (kv.length == 1) {
                    LOG.warn(
                            "Error while trying to split key and value in configuration file "
                                    + file
                                    + ":"
                                    + lineNo
                                    + ": \""
                                    + line
                                    + "\"");
                    continue;
                }

                String key = kv[0].trim();
                String value = kv[1].trim();

                // sanity check
                if (key.length() == 0 || value.length() == 0) {
                    LOG.warn(
                            "Error after splitting key and value in configuration file "
                                    + file
                                    + ":"
                                    + lineNo
                                    + ": \""
                                    + line
                                    + "\"");
                    continue;
                }

                LOG.info(
                        "Loading configuration property: {}, {}",
                        key,
                        isSensitive(key) ? HIDDEN_CONTENT : value);
                config.setString(key, value);
            }
        }
    } catch (IOException e) {
        throw new RuntimeException("Error parsing YAML configuration.", e);
    }

    return config;
}
```

从`flink-conf.yaml`中获取其中的`key-value`的值，然后存入到`Configuration`对象中，其实`Configuration`对象就是一个`HashMap`的实现。

```java
/** Creates a new empty configuration. */
public Configuration() {
    this.confData = new HashMap<>();
}
```

#### 5. StandaloneSessionClusterEntrypoint

创建`StandaloneSessionClusterEntrypoint`其实是调用了父类的父类`ClusterEntrypoint`的构造函数，这个构造方法如下：

```java
// StandaloneSessionClusterEntrypoint
public StandaloneSessionClusterEntrypoint(Configuration configuration) {
    super(configuration);
}

// SessionClusterEntrypoint
public SessionClusterEntrypoint(Configuration configuration) {
    super(configuration);
}

// ClusterEntrypoint
protected ClusterEntrypoint(Configuration configuration) {
    this.configuration = generateClusterConfiguration(configuration);
    this.terminationFuture = new CompletableFuture<>();

    if (configuration.get(JobManagerOptions.SCHEDULER_MODE) == SchedulerExecutionMode.REACTIVE
            && !supportsReactiveMode()) {
        final String msg =
                "Reactive mode is configured for an unsupported cluster type. At the moment, reactive mode is only supported by standalone application clusters (bin/standalone-job.sh).";
        // log message as well, otherwise the error is only shown in the .out file of the
        // cluster
        LOG.error(msg);
        throw new IllegalConfigurationException(msg);
    }

    shutDownHook =
            ShutdownHookUtil.addShutdownHook(
                    () -> this.closeAsync().join(), getClass().getSimpleName(), LOG);
}
```

#### 6. runClusterEntrypoint

通过`ClusterEntrypoint`的构造方法创建`StandaloneSessionClusterEntrypoint`对象后，将该对象传入`ClusterEntrypoint`类的`runClusterEntrypoint`方法中。

```java
public static void runClusterEntrypoint(ClusterEntrypoint clusterEntrypoint) {

    final String clusterEntrypointName = clusterEntrypoint.getClass().getSimpleName();
    try {
        // 调用ClusterEntrypoint的startCluster方法
        clusterEntrypoint.startCluster();
    } catch (ClusterEntrypointException e) {
        LOG.error(
                String.format("Could not start cluster entrypoint %s.", clusterEntrypointName),
                e);
        System.exit(STARTUP_FAILURE_RETURN_CODE);
    }

    int returnCode;
    Throwable throwable = null;

    try {
        returnCode = clusterEntrypoint.getTerminationFuture().get().processExitCode();
    } catch (Throwable e) {
        throwable = ExceptionUtils.stripExecutionException(e);
        returnCode = RUNTIME_FAILURE_RETURN_CODE;
    }

    LOG.info(
            "Terminating cluster entrypoint process {} with exit code {}.",
            clusterEntrypointName,
            returnCode,
            throwable);
    System.exit(returnCode);
}
```

我们可以看到在`runClusterEntrypoint`方法中继续调用了`startCluster`方法，继续看`startCluster`方法的实现：

```java
public void startCluster() throws ClusterEntrypointException {
    LOG.info("Starting {}.", getClass().getSimpleName());

    try {
        FlinkSecurityManager.setFromConfiguration(configuration);
        PluginManager pluginManager =cc
                PluginUtils.createPluginManagerFromRootFolder(configuration);
        // 内部调用FileSystem.initialize()初始化配置文件和PluginManager的共享文件设置
        // PluginManager是负责管理使用单独类加载的集群插件加载程序
        configureFileSystems(configuration, pluginManager);

        // 内部调用SecurityUtils.install配置安全相关的配置
        SecurityContext securityContext = installSecurityContext(configuration);

        securityContext.runSecured(
                (Callable<Void>)
                        () -> {
                            // 主方法
                            runCluster(configuration, pluginManager);

                            return null;
                        });
    } catch (Throwable t) {
        final Throwable strippedThrowable =
                ExceptionUtils.stripException(t, UndeclaredThrowableException.class);

        try {
            // clean up any partial state
            shutDownAsync(
                            ApplicationStatus.FAILED,
                            ShutdownBehaviour.STOP_APPLICATION,
                            ExceptionUtils.stringifyException(strippedThrowable),
                            false)
                    .get(
                            INITIALIZATION_SHUTDOWN_TIMEOUT.toMilliseconds(),
                            TimeUnit.MILLISECONDS);
        } catch (InterruptedException | ExecutionException | TimeoutException e) {
            strippedThrowable.addSuppressed(e);
        }

        throw new ClusterEntrypointException(
                String.format(
                        "Failed to initialize the cluster entrypoint %s.",
                        getClass().getSimpleName()),
                strippedThrowable);
    }
}
```

继续深入看看`runCluster`方法的实现：

```java
private void runCluster(Configuration configuration, PluginManager pluginManager)
        throws Exception {
    // 对方法所有内容加锁
    synchronized (lock) {
        // 初始化服务，做好准备工作 1️⃣
        initializeServices(configuration, pluginManager);

        // write host information into configuration
        // 将jobmanager地址写入配置，包括主机地址和端口号
        configuration.setString(JobManagerOptions.ADDRESS, commonRpcService.getAddress());
        configuration.setInteger(JobManagerOptions.PORT, commonRpcService.getPort());

        // DispatcherResourceManagerComponent组件创建的抽象类
        final DispatcherResourceManagerComponentFactory
                dispatcherResourceManagerComponentFactory =
                        createDispatcherResourceManagerComponentFactory(configuration);

        // 创建Dispatcher的资源管理器 2️⃣
        // 开启的服务包括：RPC服务、HA服务、blob服务、心跳检查服务以及metric服务
        clusterComponent =
                dispatcherResourceManagerComponentFactory.create(
                        configuration,
                        ioExecutor,
                        commonRpcService,
                        haServices,
                        blobServer,
                        heartbeatServices,
                        metricRegistry,
                        executionGraphInfoStore,
                        new RpcMetricQueryServiceRetriever(
                                metricRegistry.getMetricQueryServiceRpcService()),
                        this);

        clusterComponent
                .getShutDownFuture()
                .whenComplete(
                        (ApplicationStatus applicationStatus, Throwable throwable) -> {
                            if (throwable != null) {
                                shutDownAsync(
                                        ApplicationStatus.UNKNOWN,
                                        ShutdownBehaviour.STOP_APPLICATION,
                                        ExceptionUtils.stringifyException(throwable),
                                        false);
                            } else {
                                // This is the general shutdown path. If a separate more
                                // specific shutdown was
                                // already triggered, this will do nothing
                                shutDownAsync(
                                        applicationStatus,
                                        ShutdownBehaviour.STOP_APPLICATION,
                                        null,
                                        true);
                            }
                        });
    }
}
```

其中`initializeServices`具体实现如下，其中初始化了RPC服务、HA服务、blob服务、心跳检查服务以及metric注册服务。

```java
protected void initializeServices(Configuration configuration, PluginManager pluginManager)
        throws Exception {

    LOG.info("Initializing cluster services.");

    synchronized (lock) {
        // 创建RPC服务
        commonRpcService =
                AkkaRpcServiceUtils.createRemoteRpcService(
                        configuration,
                        configuration.getString(JobManagerOptions.ADDRESS),
                        getRPCPortRange(configuration),
                        configuration.getString(JobManagerOptions.BIND_HOST),
                        configuration.getOptional(JobManagerOptions.RPC_BIND_PORT));

        JMXService.startInstance(configuration.getString(JMXServerOptions.JMX_SERVER_PORT));

        // update the configuration used to create the high availability services
        // 更新HA服务的配置，包括hostname和port
        configuration.setString(JobManagerOptions.ADDRESS, commonRpcService.getAddress());
        configuration.setInteger(JobManagerOptions.PORT, commonRpcService.getPort());

        ioExecutor =
                Executors.newFixedThreadPool(
                        ClusterEntrypointUtils.getPoolSize(configuration),
                        new ExecutorThreadFactory("cluster-io"));
        // 创建HA服务
        haServices = createHaServices(configuration, ioExecutor);
        // 创建blob服务
        blobServer = new BlobServer(configuration, haServices.createBlobStore());
        blobServer.start();
        // 创建心跳检查服务
        heartbeatServices = createHeartbeatServices(configuration);
        // 创建metric注册服务，该服务充当MetricGroup和MetricReporter之间的连接
        metricRegistry = createMetricRegistry(configuration, pluginManager);

        // 开启MetricQueryService
        final RpcService metricQueryServiceRpcService =
                MetricUtils.startRemoteMetricsRpcService(
                        configuration, commonRpcService.getAddress());
        metricRegistry.startQueryService(metricQueryServiceRpcService, null);

        final String hostname = RpcUtils.getHostname(commonRpcService);

        // 实例化processMetricGroup
        processMetricGroup =
                MetricUtils.instantiateProcessMetricGroup(
                        metricRegistry,
                        hostname,
                        ConfigurationUtils.getSystemResourceMetricsProbingInterval(
                                configuration));

        // ExecutionGraph图
        executionGraphInfoStore =
                createSerializableExecutionGraphStore(
                        configuration, commonRpcService.getScheduledExecutor());
    }
}
```

之后继续看`clusterComponent`对应的服务开启部分的实现，目前只有一个`DefaultDispatcherResourceManagerComponentFactory`的实现：

```java
// DispatcherResourceManagerComponentFactory
public interface DispatcherResourceManagerComponentFactory {

    DispatcherResourceManagerComponent create(
            Configuration configuration,
            Executor ioExecutor,
            RpcService rpcService,
            HighAvailabilityServices highAvailabilityServices,
            BlobServer blobServer,
            HeartbeatServices heartbeatServices,
            MetricRegistry metricRegistry,
            ExecutionGraphInfoStore executionGraphInfoStore,
            MetricQueryServiceRetriever metricQueryServiceRetriever,
            FatalErrorHandler fatalErrorHandler)
            throws Exception;
}
```

![](https://yanko24-note.oss-cn-zhangjiakou.aliyuncs.com/flink-sourcecode/DefaultDispatcherResourceManagerComponentFactory.png)

接下来看`DefaultDispatcherResourceManagerComponentFactory#create`方法的具体内容：

```java
@Override
public DispatcherResourceManagerComponent create(
        Configuration configuration,
        Executor ioExecutor,
        RpcService rpcService,
        HighAvailabilityServices highAvailabilityServices,
        BlobServer blobServer,
        HeartbeatServices heartbeatServices,
        MetricRegistry metricRegistry,
        ExecutionGraphInfoStore executionGraphInfoStore,
        MetricQueryServiceRetriever metricQueryServiceRetriever,
        FatalErrorHandler fatalErrorHandler)
        throws Exception {

    LeaderRetrievalService dispatcherLeaderRetrievalService = null;
    LeaderRetrievalService resourceManagerRetrievalService = null;
    WebMonitorEndpoint<?> webMonitorEndpoint = null;
    ResourceManager<?> resourceManager = null;
    DispatcherRunner dispatcherRunner = null;

    try {
        dispatcherLeaderRetrievalService =
                highAvailabilityServices.getDispatcherLeaderRetriever();

        resourceManagerRetrievalService =
                highAvailabilityServices.getResourceManagerLeaderRetriever();

        // 调度程序的网关
        final LeaderGatewayRetriever<DispatcherGateway> dispatcherGatewayRetriever =
                new RpcGatewayRetriever<>(
                        rpcService,
                        DispatcherGateway.class,
                        DispatcherId::fromUuid,
                        new ExponentialBackoffRetryStrategy(
                                12, Duration.ofMillis(10), Duration.ofMillis(50)));

        // 资源调度的网关
        final LeaderGatewayRetriever<ResourceManagerGateway> resourceManagerGatewayRetriever =
                new RpcGatewayRetriever<>(
                        rpcService,
                        ResourceManagerGateway.class,
                        ResourceManagerId::fromUuid,
                        new ExponentialBackoffRetryStrategy(
                                12, Duration.ofMillis(10), Duration.ofMillis(50)));

        final ScheduledExecutorService executor =
                WebMonitorEndpoint.createExecutorService(
                        configuration.getInteger(RestOptions.SERVER_NUM_THREADS),
                        configuration.getInteger(RestOptions.SERVER_THREAD_PRIORITY),
                        "DispatcherRestEndpoint");

        final long updateInterval =
                configuration.getLong(MetricOptions.METRIC_FETCHER_UPDATE_INTERVAL);
        final MetricFetcher metricFetcher =
                updateInterval == 0
                        ? VoidMetricFetcher.INSTANCE
                        : MetricFetcherImpl.fromConfiguration(
                                configuration,
                                metricQueryServiceRetriever,
                                dispatcherGatewayRetriever,
                                executor);

        // 创建Rest Endpoint
        webMonitorEndpoint =
                restEndpointFactory.createRestEndpoint(
                        configuration,
                        dispatcherGatewayRetriever,
                        resourceManagerGatewayRetriever,
                        blobServer,
                        executor,
                        metricFetcher,
                        highAvailabilityServices.getClusterRestEndpointLeaderElectionService(),
                        fatalErrorHandler);

        log.debug("Starting Dispatcher REST endpoint.");
        // 开启
        webMonitorEndpoint.start();

        final String hostname = RpcUtils.getHostname(rpcService);

        // 创建资源管理器
        resourceManager =
                resourceManagerFactory.createResourceManager(
                        configuration,
                        ResourceID.generate(),
                        rpcService,
                        highAvailabilityServices,
                        heartbeatServices,
                        fatalErrorHandler,
                        new ClusterInformation(hostname, blobServer.getPort()),
                        webMonitorEndpoint.getRestBaseUrl(),
                        metricRegistry,
                        hostname,
                        ioExecutor);

        // JobManager中已完成作业的存档
        final HistoryServerArchivist historyServerArchivist =
                HistoryServerArchivist.createHistoryServerArchivist(
                        configuration, webMonitorEndpoint, ioExecutor);

        // 部分调度服务，该部分需要在提供给Dispatcher之前完成
        final PartialDispatcherServices partialDispatcherServices =
                new PartialDispatcherServices(
                        configuration,
                        highAvailabilityServices,
                        resourceManagerGatewayRetriever,
                        blobServer,
                        heartbeatServices,
                        // JobManager的metric数据
                        () ->
                                MetricUtils.instantiateJobManagerMetricGroup(
                                        metricRegistry, hostname),
                        executionGraphInfoStore,
                        fatalErrorHandler,
                        historyServerArchivist,
                        metricRegistry.getMetricQueryServiceGatewayRpcAddress(),
                        ioExecutor);

        log.debug("Starting Dispatcher.");
        // 创建调度器
        dispatcherRunner =
                dispatcherRunnerFactory.createDispatcherRunner(
                        highAvailabilityServices.getDispatcherLeaderElectionService(),
                        fatalErrorHandler,
                        new HaServicesJobGraphStoreFactory(highAvailabilityServices),
                        ioExecutor,
                        rpcService,
                        partialDispatcherServices);

        log.debug("Starting ResourceManager.");
        // 开启资源管理器
        resourceManager.start();

        // 开启资源调取网关
        resourceManagerRetrievalService.start(resourceManagerGatewayRetriever);
        // 开启调度程序网关
        dispatcherLeaderRetrievalService.start(dispatcherGatewayRetriever);

        return new DispatcherResourceManagerComponent(
                dispatcherRunner,
                DefaultResourceManagerService.createFor(resourceManager),
                dispatcherLeaderRetrievalService,
                resourceManagerRetrievalService,
                webMonitorEndpoint,
                fatalErrorHandler);

    } catch (Exception exception) {
        // clean up all started components
        if (dispatcherLeaderRetrievalService != null) {
            try {
                dispatcherLeaderRetrievalService.stop();
            } catch (Exception e) {
                exception = ExceptionUtils.firstOrSuppressed(e, exception);
            }
        }

        if (resourceManagerRetrievalService != null) {
            try {
                resourceManagerRetrievalService.stop();
            } catch (Exception e) {
                exception = ExceptionUtils.firstOrSuppressed(e, exception);
            }
        }

        final Collection<CompletableFuture<Void>> terminationFutures = new ArrayList<>(3);

        if (webMonitorEndpoint != null) {
            terminationFutures.add(webMonitorEndpoint.closeAsync());
        }

        if (resourceManager != null) {
            terminationFutures.add(resourceManager.closeAsync());
        }

        if (dispatcherRunner != null) {
            terminationFutures.add(dispatcherRunner.closeAsync());
        }

        final FutureUtils.ConjunctFuture<Void> terminationFuture =
                FutureUtils.completeAll(terminationFutures);

        try {
            terminationFuture.get();
        } catch (Exception e) {
            exception = ExceptionUtils.firstOrSuppressed(e, exception);
        }

        throw new FlinkException(
                "Could not create the DispatcherResourceManagerComponent.", exception);
    }
}
```

上面中创建资源管理器对应的在下面的类中都有自己的实现：

![](https://yanko24-note.oss-cn-zhangjiakou.aliyuncs.com/flink-sourcecode/DispatcherResourceManagerComponent.png)

我们接下来只看看在`StandaloneResourceManagerFactory`中的具体实现：

```java
@Override
protected ResourceManager<ResourceID> createResourceManager(
        Configuration configuration,
        ResourceID resourceId,
        RpcService rpcService,
        HighAvailabilityServices highAvailabilityServices,
        HeartbeatServices heartbeatServices,
        FatalErrorHandler fatalErrorHandler,
        ClusterInformation clusterInformation,
        @Nullable String webInterfaceUrl,
        ResourceManagerMetricGroup resourceManagerMetricGroup,
        ResourceManagerRuntimeServices resourceManagerRuntimeServices,
        Executor ioExecutor) {

    final Time standaloneClusterStartupPeriodTime =
            ConfigurationUtils.getStandaloneClusterStartupPeriodTime(configuration);

    return new StandaloneResourceManager(
            rpcService,
            resourceId,
            highAvailabilityServices,
            heartbeatServices,
            resourceManagerRuntimeServices.getSlotManager(),
            ResourceManagerPartitionTrackerImpl::new,
            resourceManagerRuntimeServices.getJobLeaderIdService(),
            clusterInformation,
            fatalErrorHandler,
            resourceManagerMetricGroup,
            standaloneClusterStartupPeriodTime,
            AkkaUtils.getTimeoutAsTime(configuration),
            ioExecutor);
}
```

到这里，整个Flink集群的启动流程就差不多了，大致流程图如下，其中有一些方法的内部如果自己感兴趣可以继续深入看看。

![](https://yanko24-note.oss-cn-zhangjiakou.aliyuncs.com/flink-sourcecode/StandaloneSessionClusterEntrypoint-start.png)

#### 7. 总结

通过对Flink集群启动流程的代码的阅读，了解了Flink集群启动的一个简单流程，总体来说包含四个步骤，分别是：解析参数`parseParametersOrExit`、加载配置`loadConfiguration`、构建`StandaloneSessionClusterEntrypoint`对象、启动集群`runClusterEntrypoint`。具体流程如下：

![](https://yanko24-note.oss-cn-zhangjiakou.aliyuncs.com/flink-sourcecode/StandaloneSessionClusterEntrypoint-process.png)

---

<div align=center>
    <font color='red' size=5>关注微信公众号《零基础学大数据》回复【Flink】领取全部PDF</font>
</div>